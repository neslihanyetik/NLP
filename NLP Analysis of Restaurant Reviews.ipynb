{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6dd75ac-2d14-4fb5-b1ab-67059b5ae3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e21e51d-5c20-441f-b659-5b5023b50f39",
   "metadata": {},
   "source": [
    "Description of the dataset to be used:\n",
    " \n",
    "\n",
    "- Columns separated by \\t (tab space)\n",
    "- First column is about reviews of people\n",
    "- In second column, 0 is for negative review and 1 is for positive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84d81316-e45a-48a7-8878-a584943180b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Restaurant_Reviews.tsv\",delimiter =\"\\t\", quoting =3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00887c5d-6af2-4a71-bcc1-1e9b670f981d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3453406b-36eb-4754-89f8-7e339e0eeb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  1000 non-null   object\n",
      " 1   Liked   1000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31e3664d-d2cc-4ddf-bac3-794177c67be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1d792d-cfea-4176-8658-2e67b72dcf7a",
   "metadata": {},
   "source": [
    "Hedefimiz, bu veri setinden bir model oluşturmak ve yeni inceleme metninin olumlu veya olumsuz olduğunu tahmin etmektir. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f0e549-9897-4a27-8a4d-c4396f53de28",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b89db0f-143e-44fb-b439-64ac0d48a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # library to clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9c3a681-9d7e-4e19-becb-0b81ed09dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = re.sub(\"[^a-zA-Z]\",\" \",df[\"Review\"][0])\n",
    "\n",
    "# The first parameter [^a-zA-Z] is the characters that are not removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e63e79a-3c22-4f99-aab3-8fa01ec722c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wow    Loved this place '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7539a4a2-b6b1-4c5d-9211-33a5920408b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the selection on the menu was great and so were the prices \n",
      "['The', 'selection', 'on', 'the', 'menu', 'was', 'great', 'and', 'so', 'were', 'the', 'prices']\n"
     ]
    }
   ],
   "source": [
    "review = re.sub(\"[^a-zA-Z]\",\" \",df[\"Review\"][4])\n",
    "print(review.lower())\n",
    "print(review.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61ba064e-9de6-4ab2-98fb-b762417bb047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/neslihanyetik/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Natural Language Tool Kit\n",
    "import nltk\n",
    " \n",
    "nltk.download('stopwords')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ad5ef54-5dba-4d5b-9cbd-bec5e3bf4805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Stemming propose\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d3e2ced-8d9a-46e4-a529-e5a2e48a6ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1699fe17-85e7-49cb-8d4a-4f313df19be7",
   "metadata": {},
   "outputs": [],
   "source": [
    " from nltk.corpus import stopwords # corpus: değerler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1404dda7-acee-4887-a5ba-7c5ce0fd0831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'e',\n",
       " 'l',\n",
       " 'e',\n",
       " 'c',\n",
       " 'n',\n",
       " ' ',\n",
       " 'n',\n",
       " ' ',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'e',\n",
       " 'n',\n",
       " 'u',\n",
       " ' ',\n",
       " 'w',\n",
       " ' ',\n",
       " 'g',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'n',\n",
       " ' ',\n",
       " ' ',\n",
       " 'w',\n",
       " 'e',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'p',\n",
       " 'r',\n",
       " 'c',\n",
       " 'e',\n",
       " ' ']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop for stemming each word\n",
    "# in string array at ith row   \n",
    "# kelimenin gövdesini bulmuş oluyoruz.\n",
    "review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39a099b2-4901-4908-b429-6b77e98879d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t h e   e l e c n   n   h e   e n u   w   g r e   n     w e r e   h e   p r c e  '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rejoin all string array elements\n",
    "# to create back into a string\n",
    "review = ' '.join(review) \n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676e6a5d-1e78-4d25-b270-133a7ac2fceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9f56557-15bb-40cf-ae9b-d57c20e0ff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty array\n",
    "# to append clean text\n",
    "corpus = []\n",
    " \n",
    "# 1000 (reviews) rows to clean\n",
    "for i in range(0, 1000):\n",
    "     \n",
    "    # column : \"Review\", row ith\n",
    "    review = re.sub('[^a-zA-Z]', ' ', df['Review'][i])\n",
    "     \n",
    "    # convert all cases to lower cases\n",
    "    review = review.lower()\n",
    "     \n",
    "    # split to array(default delimiter is \" \")\n",
    "    review = review.split()\n",
    "     \n",
    "    # creating PorterStemmer object to\n",
    "    # take main stem of each word\n",
    "    ps = PorterStemmer()\n",
    "     \n",
    "    # loop for stemming each word\n",
    "    # in string array at ith row   \n",
    "    review = [ps.stem(word) for word in review\n",
    "                if not word in set(stopwords.words('english'))]\n",
    "                 \n",
    "    # rejoin all string array elements\n",
    "    # to create back into a string\n",
    "    review = ' '.join(review) \n",
    "     \n",
    "    # append each string to create\n",
    "    # array of clean text\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86caf034-2216-40ad-927a-f75fe2bb4d81",
   "metadata": {},
   "source": [
    "### Feature Engineering and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a1d73d6-39a8-46f0-9ddf-e5ef499312bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b7f4f6a-d473-4c50-8211-307c0bac0821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To extract max 1500 feature.\n",
    "# \"max_features\" is attribute to\n",
    "# experiment with to get better results\n",
    "# \"max_features\" ile kelime frekansını ayarlıyoruz\n",
    "cv = CountVectorizer(max_features = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43f82004-1702-4915-ab12-05c840b56a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X contains corpus (dependent variable)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    " \n",
    "# y contains answers if review\n",
    "# is positive or negative\n",
    "y = df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "475a06d4-8065-4e67-a1f7-08f7f99826b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into\n",
    "# the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    " \n",
    "# experiment with \"test_size\"\n",
    "# to get better results\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a12f7674-19cb-4686-953e-e0d13a00a929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=501)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Classification\n",
    "# to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    " \n",
    "# n_estimators can be said as number of\n",
    "# trees, experiment with n_estimators\n",
    "# to get better results\n",
    "model = RandomForestClassifier(n_estimators = 501,\n",
    "                            criterion = 'entropy')\n",
    "                             \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61473627-622f-4188-96ef-e8905c1cea99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = model.predict(X_test)\n",
    " \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be707cf6-de49-4b7e-aeb4-68a1da9615e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100,  18],\n",
       "       [ 48,  84]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    " \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    " \n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474c3cad-555c-4b1a-8acb-e2b14bf73cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b84c4b7-1b75-4105-8ead-0e1bdfe5897e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94df00d2-8453-4a9e-8091-8ad412d90b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
